
ðŸ“„ Overview

This repository contains a script that automatically collects metadata for Arabic datasets available on the Hugging Face Hub. The collected metadata includes:
	â€¢	Task
	â€¢	Dataset Name
	â€¢	Likes
	â€¢	Downloads
	â€¢	Last Modified Date
	â€¢	License
	â€¢	Models Used
	â€¢	Size of Downloaded Files
	â€¢	Size of Downloaded Files (in bytes)
	â€¢	Size of Parquet Files
	â€¢	Size of Parquet Files (in bytes)
	â€¢	Number of Rows
	â€¢	ArXiv Paper
	â€¢	ACL Paper
	â€¢	README File
	â€¢	README Quality Level
	â€¢	README Quality Score

The datasets are organized into the following 12 NLP task categories:
	1.	Question Answering (Q&A)
	2.	Translation
	3.	Reasoning & Multi-step Thinking
	4.	Summarization
	5.	Cultural Alignment
	6.	Dialog / Conversation
	7.	Persona Ownership / System Prompt
	8.	Robustness & Safety
	9.	Function Call
	10.	Ethics, Bias, and Fairness
	11.	Code Generation
	12.	Official Documentation
