{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babd7231-46ae-4556-955c-03dda1623dc0",
   "metadata": {},
   "source": [
    "# Listing tasks (using filters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db0c75f-e085-42b1-860f-6e33a02b3968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing task: Q&A (question-answering)\n",
      "üîç Processing task: Reasoning & Multi-step Thinking (reasoning)\n",
      "üîç Processing task: Summarization (summarization)\n",
      "üîç Processing task: Cultural Alignment (cultural-aligned)\n",
      "üîç Processing task: Dialog/Conversation (conversational)\n",
      "üîç Processing task: Personal Ownership/System Prompt (System Prompt)\n",
      "üîç Processing task: Robustness & Safety (Safety)\n",
      "üîç Processing task: Function Call (function-call)\n",
      "üîç Processing task: Ethics, Bias, and Fairness (bias-and-fairness)\n",
      "üîç Processing task: Code Generation (Code Generation)\n",
      "üîç Processing task: Official Documentation (documentation)\n",
      "üîç Processing task: Translation (translation)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Mapping your task list to Hugging Face task_categories\n",
    "task_mapping = {\n",
    "    \"Q&A\": \"question-answering\",\n",
    "    \"Reasoning & Multi-step Thinking\": \"reasoning\",\n",
    "    \"Summarization\": \"summarization\",\n",
    "    \"Cultural Alignment\": \"cultural-aligned\",\n",
    "    \"Dialog/Conversation\": \"conversational\",\n",
    "    \"Personal Ownership/System Prompt\": \"System Prompt\",  \n",
    "    \"Robustness & Safety\": \"Safety\",\n",
    "    \"Function Call\": \"function-call\",  \n",
    "    \"Ethics, Bias, and Fairness\": \"bias-and-fairness\",\n",
    "    \"Code Generation\": \"Code Generation\",\n",
    "    \"Official Documentation\": \"documentation\",\n",
    "    \"Translation\": \"translation\"\n",
    "}\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# Loop through each task\n",
    "for user_task, hf_task in task_mapping.items():\n",
    "    print(f\"üîç Processing task: {user_task} ({hf_task})\")\n",
    "    try:\n",
    "        datasets_list = list_datasets(task_categories=hf_task, language=\"ar\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to fetch for task {user_task}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for dataset in datasets_list:\n",
    "        tags = dataset.tags if hasattr(dataset, \"tags\") else []\n",
    "\n",
    "        try:\n",
    "            license = [tag for tag in dataset.tags if \"license\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "\n",
    "\n",
    "        all_rows.append({\n",
    "            \"Task\": user_task,\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        \n",
    "        })\n",
    "\n",
    "# Create DataFrame and save\n",
    "df = pd.DataFrame(all_rows)\n",
    "# df\n",
    "#df.to_csv(\"arabic_multitask_datasets.csv\", index=False)\n",
    "#print(\"‚úÖ Saved to arabic_multitask_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7a859a-06e7-4eb9-87b2-444df0440372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>trais-lab/DCA-Bench</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>2025-05-31 06:02:50+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2406.07275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>AmazonScience/xtr-wiki_qa</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>2023-07-24 17:32:38+00:00</td>\n",
       "      <td>cdla-permissive-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>nthakur/swim-ir-monolingual</td>\n",
       "      <td>8</td>\n",
       "      <td>236</td>\n",
       "      <td>2024-04-28 05:12:53+00:00</td>\n",
       "      <td>cc-by-sa-4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2311.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>ClusterlabAi/InstAr-500k</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>2024-07-30 16:41:57+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>stanford-oval/ccnews</td>\n",
       "      <td>20</td>\n",
       "      <td>1949</td>\n",
       "      <td>2024-08-31 17:28:13+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Translation</td>\n",
       "      <td>IbrahimAmin/egyptian-arabic-fake-reviews</td>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "      <td>2025-05-10 14:01:01+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Translation</td>\n",
       "      <td>taha-alnasser/ArzEn-CodeMixed</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2025-05-09 03:38:16+00:00</td>\n",
       "      <td>afl-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Translation</td>\n",
       "      <td>Hamzah-Asadullah/TinyDS-20k</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>2025-05-25 19:22:17+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Translation</td>\n",
       "      <td>Groovy-123/deep-think</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>2025-05-22 06:06:36+00:00</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Translation</td>\n",
       "      <td>freococo/quran_multilingual_parallel</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2025-05-30 12:00:27+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Task                                Dataset ID  Likes  Downloads  \\\n",
       "0            Q&A                       trais-lab/DCA-Bench      2         77   \n",
       "1            Q&A                 AmazonScience/xtr-wiki_qa      5         67   \n",
       "2            Q&A               nthakur/swim-ir-monolingual      8        236   \n",
       "3            Q&A                  ClusterlabAi/InstAr-500k     12         71   \n",
       "4            Q&A                      stanford-oval/ccnews     20       1949   \n",
       "..           ...                                       ...    ...        ...   \n",
       "364  Translation  IbrahimAmin/egyptian-arabic-fake-reviews      2        228   \n",
       "365  Translation             taha-alnasser/ArzEn-CodeMixed      0         47   \n",
       "366  Translation               Hamzah-Asadullah/TinyDS-20k      1         58   \n",
       "367  Translation                     Groovy-123/deep-think      1         71   \n",
       "368  Translation      freococo/quran_multilingual_parallel      0         75   \n",
       "\n",
       "                Last Modified              License  Models     Size  \\\n",
       "0   2025-05-31 06:02:50+00:00           apache-2.0       0  unknown   \n",
       "1   2023-07-24 17:32:38+00:00  cdla-permissive-2.0       0  unknown   \n",
       "2   2024-04-28 05:12:53+00:00         cc-by-sa-4.0       7  unknown   \n",
       "3   2024-07-30 16:41:57+00:00           apache-2.0       3  unknown   \n",
       "4   2024-08-31 17:28:13+00:00                 none       0  unknown   \n",
       "..                        ...                  ...     ...      ...   \n",
       "364 2025-05-10 14:01:01+00:00                  mit       0  unknown   \n",
       "365 2025-05-09 03:38:16+00:00              afl-3.0       0  unknown   \n",
       "366 2025-05-25 19:22:17+00:00                  mit       0  unknown   \n",
       "367 2025-05-22 06:06:36+00:00                other       1  unknown   \n",
       "368 2025-05-30 12:00:27+00:00                  mit       0  unknown   \n",
       "\n",
       "          ArXiv  \n",
       "0    2406.07275  \n",
       "1          none  \n",
       "2    2311.05800  \n",
       "3          none  \n",
       "4          none  \n",
       "..          ...  \n",
       "364        none  \n",
       "365        none  \n",
       "366        none  \n",
       "367        none  \n",
       "368        none  \n",
       "\n",
       "[369 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4dc348-be37-4db4-9dc9-1f0d6a7f2395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task\n",
       "Q&A              165\n",
       "Translation      157\n",
       "Summarization     47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Task'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51196c-fc81-48a8-8d0d-518a1e92c2ff",
   "metadata": {},
   "source": [
    "# Listing tasks (using keywords):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48262d-e7af-4339-b181-0ca14bb0f1b2",
   "metadata": {},
   "source": [
    "## Cultural Alignment Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75e3179a-ad1f-478b-b685-f11bafa320a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreedomIntelligence/ACVA-Arabic-Cultural-Value-Alignment 8 2023-09-21 12:39:18+00:00 apache-2.0 2 unknown none\n",
      "arbml/CIDAR 50 2025-04-03 08:35:36+00:00 apache-2.0 4 unknown 2402.03177\n",
      "arbml/CIDAR-EVAL-100 2 2024-02-14 15:46:10+00:00 apache-2.0 0 unknown 2402.03177\n",
      "arbml/CIDAR-MCQ-100 4 2024-04-02 14:48:39+00:00 apache-2.0 0 unknown 2402.03177\n",
      "QCRI/MultiNativQA 0 2024-10-25 10:59:30+00:00 cc-by-nc-sa-4.0 0 unknown 2407.09823\n",
      "Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU 2 2025-02-20 17:22:43+00:00 apache-2.0 0 unknown none\n",
      "MBZUAI/ArabCulture 10 2025-05-23 08:38:06+00:00 cc-by-nc-sa-4.0 0 unknown 2502.12788\n",
      "HabibaAbderrahim/Tunisian-Proverbs-with-Image-Associations-A-Cultural-and-Linguistic-Dataset 0 2025-05-07 09:16:57+00:00 cc-by-4.0 0 unknown none\n",
      "QCRI/SpokenNativQA 0 2025-05-29 23:03:37+00:00 cc-by-nc-sa-4.0 0 unknown 2505.19163\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"cultural\", \"culture\", \"cidar\"]\n",
    "required_tags = [\"cultural-aligned\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match or tag_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Tags\": \", \".join(dataset_tags),\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eba430d-7c51-431f-ad1a-251848ee8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FreedomIntelligence/ACVA-Arabic-Cultural-Value...</td>\n",
       "      <td>8</td>\n",
       "      <td>101</td>\n",
       "      <td>2023-09-21 12:39:18+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>language:ar, license:apache-2.0, size_categori...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arbml/CIDAR</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>2025-04-03 08:35:36+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>task_categories:text-generation, language:ar, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2402.03177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arbml/CIDAR-EVAL-100</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2024-02-14 15:46:10+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:text-generation, language:ar, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2402.03177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arbml/CIDAR-MCQ-100</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>2024-04-02 14:48:39+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:multiple-choice, language:ar, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2402.03177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCRI/MultiNativQA</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>2024-10-25 10:59:30+00:00</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:question-answering, language:a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2407.09823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Omartificial-Intelligence-Space/ILMAAM-Arabic-...</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-02-20 17:22:43+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>language:ar, license:apache-2.0, size_categori...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MBZUAI/ArabCulture</td>\n",
       "      <td>10</td>\n",
       "      <td>847</td>\n",
       "      <td>2025-05-23 08:38:06+00:00</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:multiple-choice, task_categori...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2502.12788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HabibaAbderrahim/Tunisian-Proverbs-with-Image-...</td>\n",
       "      <td>0</td>\n",
       "      <td>606</td>\n",
       "      <td>2025-05-07 09:16:57+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:text2text-generation, task_cat...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QCRI/SpokenNativQA</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>2025-05-29 23:03:37+00:00</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:question-answering, language:a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2505.19163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset ID  Likes  Downloads  \\\n",
       "0  FreedomIntelligence/ACVA-Arabic-Cultural-Value...      8        101   \n",
       "1                                        arbml/CIDAR     50        240   \n",
       "2                               arbml/CIDAR-EVAL-100      2         22   \n",
       "3                                arbml/CIDAR-MCQ-100      4         63   \n",
       "4                                  QCRI/MultiNativQA      0        193   \n",
       "5  Omartificial-Intelligence-Space/ILMAAM-Arabic-...      2         27   \n",
       "6                                 MBZUAI/ArabCulture     10        847   \n",
       "7  HabibaAbderrahim/Tunisian-Proverbs-with-Image-...      0        606   \n",
       "8                                 QCRI/SpokenNativQA      0        111   \n",
       "\n",
       "              Last Modified          License  Models  \\\n",
       "0 2023-09-21 12:39:18+00:00       apache-2.0       2   \n",
       "1 2025-04-03 08:35:36+00:00       apache-2.0       4   \n",
       "2 2024-02-14 15:46:10+00:00       apache-2.0       0   \n",
       "3 2024-04-02 14:48:39+00:00       apache-2.0       0   \n",
       "4 2024-10-25 10:59:30+00:00  cc-by-nc-sa-4.0       0   \n",
       "5 2025-02-20 17:22:43+00:00       apache-2.0       0   \n",
       "6 2025-05-23 08:38:06+00:00  cc-by-nc-sa-4.0       0   \n",
       "7 2025-05-07 09:16:57+00:00        cc-by-4.0       0   \n",
       "8 2025-05-29 23:03:37+00:00  cc-by-nc-sa-4.0       0   \n",
       "\n",
       "                                                Tags     Size       ArXiv  \n",
       "0  language:ar, license:apache-2.0, size_categori...  unknown        none  \n",
       "1  task_categories:text-generation, language:ar, ...  unknown  2402.03177  \n",
       "2  task_categories:text-generation, language:ar, ...  unknown  2402.03177  \n",
       "3  task_categories:multiple-choice, language:ar, ...  unknown  2402.03177  \n",
       "4  task_categories:question-answering, language:a...  unknown  2407.09823  \n",
       "5  language:ar, license:apache-2.0, size_categori...  unknown        none  \n",
       "6  task_categories:multiple-choice, task_categori...  unknown  2502.12788  \n",
       "7  task_categories:text2text-generation, task_cat...  unknown        none  \n",
       "8  task_categories:question-answering, language:a...  unknown  2505.19163  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa50af-725d-4315-9be0-471f812c00cc",
   "metadata": {},
   "source": [
    "## Reasoning & Multi-step Thinking Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b270232-b151-434c-9d04-173ef1325847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beetleware/arabic-reasoning-dataset-logic 7 2025-05-21 11:02:11+00:00 mit 0 unknown none\n",
      "MohammedNasser/ARabic_Reasoning_QA 5 2024-09-07 23:00:07+00:00 apache-2.0 1 unknown none\n",
      "MohammedNasser/Arabic_Reasoning_Instruct_QA 2 2024-09-10 07:30:48+00:00 apache-2.0 1 unknown none\n",
      "Omartificial-Intelligence-Space/Arabic_Reasoning_Dataset 9 2024-12-01 08:13:05+00:00 apache-2.0 4 unknown none\n",
      "lightblue/reasoning-multilingual-R1-Llama-70B-train 36 2025-01-31 07:04:20+00:00 apache-2.0 21 unknown none\n",
      "Jr23xd23/Arabic-Optimized-Reasoning-Dataset 2 2025-02-25 13:29:24+00:00 apache-2.0 0 unknown none\n",
      "Pinkstack/OpenHumanreasoning-multilingual-2.2k 2 2025-03-03 17:16:04+00:00 apache-2.0 0 unknown none\n",
      "miscovery/Math_CoT_Arabic_English_Reasoning 16 2025-05-12 00:14:13+00:00 mit 1 unknown none\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"Reasoning\", \"Multi-step reasoning\"]\n",
    "#required_tags = [\"logical-reasoning\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    #tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match ):# or tag_match\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            #\"Tags\": \", \".join(dataset_tags),\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d550ab-af41-4dd3-b69b-aa86e8dab169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beetleware/arabic-reasoning-dataset-logic</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>2025-05-21 11:02:11+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MohammedNasser/ARabic_Reasoning_QA</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2024-09-07 23:00:07+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MohammedNasser/Arabic_Reasoning_Instruct_QA</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2024-09-10 07:30:48+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Omartificial-Intelligence-Space/Arabic_Reasoni...</td>\n",
       "      <td>9</td>\n",
       "      <td>166</td>\n",
       "      <td>2024-12-01 08:13:05+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightblue/reasoning-multilingual-R1-Llama-70B-...</td>\n",
       "      <td>36</td>\n",
       "      <td>104</td>\n",
       "      <td>2025-01-31 07:04:20+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>21</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jr23xd23/Arabic-Optimized-Reasoning-Dataset</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-02-25 13:29:24+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pinkstack/OpenHumanreasoning-multilingual-2.2k</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-03-03 17:16:04+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miscovery/Math_CoT_Arabic_English_Reasoning</td>\n",
       "      <td>16</td>\n",
       "      <td>468</td>\n",
       "      <td>2025-05-12 00:14:13+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset ID  Likes  Downloads  \\\n",
       "0          beetleware/arabic-reasoning-dataset-logic      7         39   \n",
       "1                 MohammedNasser/ARabic_Reasoning_QA      5         20   \n",
       "2        MohammedNasser/Arabic_Reasoning_Instruct_QA      2         42   \n",
       "3  Omartificial-Intelligence-Space/Arabic_Reasoni...      9        166   \n",
       "4  lightblue/reasoning-multilingual-R1-Llama-70B-...     36        104   \n",
       "5        Jr23xd23/Arabic-Optimized-Reasoning-Dataset      2         34   \n",
       "6     Pinkstack/OpenHumanreasoning-multilingual-2.2k      2         31   \n",
       "7        miscovery/Math_CoT_Arabic_English_Reasoning     16        468   \n",
       "\n",
       "              Last Modified     License  Models     Size ArXiv  \n",
       "0 2025-05-21 11:02:11+00:00         mit       0  unknown  none  \n",
       "1 2024-09-07 23:00:07+00:00  apache-2.0       1  unknown  none  \n",
       "2 2024-09-10 07:30:48+00:00  apache-2.0       1  unknown  none  \n",
       "3 2024-12-01 08:13:05+00:00  apache-2.0       4  unknown  none  \n",
       "4 2025-01-31 07:04:20+00:00  apache-2.0      21  unknown  none  \n",
       "5 2025-02-25 13:29:24+00:00  apache-2.0       0  unknown  none  \n",
       "6 2025-03-03 17:16:04+00:00  apache-2.0       0  unknown  none  \n",
       "7 2025-05-12 00:14:13+00:00         mit       1  unknown  none  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec938e-545c-4d43-bbeb-1bcfda7425ed",
   "metadata": {},
   "source": [
    "## Dialog/Conversation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308d4475-640a-4494-9afb-33e20815566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mohamedemam/Arabic-samsum-dialogsum 1 2023-09-11 14:35:29+00:00 cc-by-nc-2.0 1 unknown 1911.12237\n",
      "m-ric/Open_Assistant_Conversation_Chains 6 2023-11-22 14:37:58+00:00 apache-2.0 0 unknown none\n",
      "premio-ai/TheArabicPile_Conversational 1 2024-03-21 21:42:33+00:00 cc-by-nc-4.0 0 unknown none\n",
      "Mars203020/arabic_medical_dialogue 3 2024-06-29 11:49:41+00:00 mit 0 unknown none\n",
      "willwade/AACConversations 0 2025-05-15 10:37:50+00:00 cc-by-4.0 0 unknown none\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"Dialog\", \"Conversation\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match ):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e08a1f9-f859-412c-8bcc-ceec5695b8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mohamedemam/Arabic-samsum-dialogsum</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>2023-09-11 14:35:29+00:00</td>\n",
       "      <td>cc-by-nc-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1911.12237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m-ric/Open_Assistant_Conversation_Chains</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>2023-11-22 14:37:58+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>premio-ai/TheArabicPile_Conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-03-21 21:42:33+00:00</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mars203020/arabic_medical_dialogue</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>2024-06-29 11:49:41+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>willwade/AACConversations</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>2025-05-15 10:37:50+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Dataset ID  Likes  Downloads  \\\n",
       "0       mohamedemam/Arabic-samsum-dialogsum      1         95   \n",
       "1  m-ric/Open_Assistant_Conversation_Chains      6         31   \n",
       "2    premio-ai/TheArabicPile_Conversational      1         29   \n",
       "3        Mars203020/arabic_medical_dialogue      3        103   \n",
       "4                 willwade/AACConversations      0         64   \n",
       "\n",
       "              Last Modified       License  Models     Size       ArXiv  \n",
       "0 2023-09-11 14:35:29+00:00  cc-by-nc-2.0       1  unknown  1911.12237  \n",
       "1 2023-11-22 14:37:58+00:00    apache-2.0       0  unknown        none  \n",
       "2 2024-03-21 21:42:33+00:00  cc-by-nc-4.0       0  unknown        none  \n",
       "3 2024-06-29 11:49:41+00:00           mit       0  unknown        none  \n",
       "4 2025-05-15 10:37:50+00:00     cc-by-4.0       0  unknown        none  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca41bf-52a0-45ff-8251-82f00fbfb318",
   "metadata": {},
   "source": [
    "## Personal Ownership/System Prompt Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275c76db-0bd1-44fd-8669-9baa27acca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"system prompt\", \"persona\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d54cb2-c490-41a1-b148-e073cf5cfaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70239f5b-820c-46b1-98f5-8490cb5486c9",
   "metadata": {},
   "source": [
    "## Robustness & Safety Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8dd7c6d-b02c-4364-bcdb-5400f1da7933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textdetox/multilingual_toxicity_dataset 27 2025-03-21 18:52:31+00:00 openrail++ 8 unknown none\n",
      "ToxicityPrompts/PolygloToxicityPrompts 11 2024-05-16 07:02:28+00:00 none 0 unknown 2405.09373\n",
      "luizapzbn/from-one-to-many-toxicity-mitigation 0 2024-05-24 17:09:53+00:00 apache-2.0 0 unknown 2403.03893\n",
      "textdetox/multilingual_toxicity_explained 1 2025-02-04 21:03:23+00:00 openrail++ 1 unknown 2412.11691\n",
      "ToxicityPrompts/PolyGuardMix 1 2025-05-16 23:35:00+00:00 cc-by-4.0 0 unknown 2504.04377\n",
      "ToxicityPrompts/PolyGuardPrompts 0 2025-04-18 03:21:04+00:00 none 0 unknown 2504.04377\n",
      "Malikeh1375/tokenizer-robustness-mmlu 0 2025-05-25 04:40:10+00:00 cc-by-4.0 0 unknown none\n",
      "Malikeh1375/code-switching-tokenizer-robustness 1 2025-05-24 04:28:43+00:00 cc-by-4.0 0 unknown none\n",
      "gravitee-io/textdetox-multilingual-toxicity-dataset 0 2025-05-27 12:10:42+00:00 openrail++ 1 unknown none\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"Robustness\", \"Safety\", \"Toxicity\", \"jailbreak\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf03bb5f-9373-4c51-bc2c-2c6e53c8a344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textdetox/multilingual_toxicity_dataset</td>\n",
       "      <td>27</td>\n",
       "      <td>759</td>\n",
       "      <td>2025-03-21 18:52:31+00:00</td>\n",
       "      <td>openrail++</td>\n",
       "      <td>8</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ToxicityPrompts/PolygloToxicityPrompts</td>\n",
       "      <td>11</td>\n",
       "      <td>515</td>\n",
       "      <td>2024-05-16 07:02:28+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2405.09373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luizapzbn/from-one-to-many-toxicity-mitigation</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>2024-05-24 17:09:53+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2403.03893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>textdetox/multilingual_toxicity_explained</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>2025-02-04 21:03:23+00:00</td>\n",
       "      <td>openrail++</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2412.11691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ToxicityPrompts/PolyGuardMix</td>\n",
       "      <td>1</td>\n",
       "      <td>197</td>\n",
       "      <td>2025-05-16 23:35:00+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2504.04377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ToxicityPrompts/PolyGuardPrompts</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>2025-04-18 03:21:04+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2504.04377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Malikeh1375/tokenizer-robustness-mmlu</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>2025-05-25 04:40:10+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Malikeh1375/code-switching-tokenizer-robustness</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>2025-05-24 04:28:43+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gravitee-io/textdetox-multilingual-toxicity-da...</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2025-05-27 12:10:42+00:00</td>\n",
       "      <td>openrail++</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset ID  Likes  Downloads  \\\n",
       "0            textdetox/multilingual_toxicity_dataset     27        759   \n",
       "1             ToxicityPrompts/PolygloToxicityPrompts     11        515   \n",
       "2     luizapzbn/from-one-to-many-toxicity-mitigation      0        193   \n",
       "3          textdetox/multilingual_toxicity_explained      1        181   \n",
       "4                       ToxicityPrompts/PolyGuardMix      1        197   \n",
       "5                   ToxicityPrompts/PolyGuardPrompts      0        102   \n",
       "6              Malikeh1375/tokenizer-robustness-mmlu      0        274   \n",
       "7    Malikeh1375/code-switching-tokenizer-robustness      1        210   \n",
       "8  gravitee-io/textdetox-multilingual-toxicity-da...      0         63   \n",
       "\n",
       "              Last Modified     License  Models     Size       ArXiv  \n",
       "0 2025-03-21 18:52:31+00:00  openrail++       8  unknown        none  \n",
       "1 2024-05-16 07:02:28+00:00        none       0  unknown  2405.09373  \n",
       "2 2024-05-24 17:09:53+00:00  apache-2.0       0  unknown  2403.03893  \n",
       "3 2025-02-04 21:03:23+00:00  openrail++       1  unknown  2412.11691  \n",
       "4 2025-05-16 23:35:00+00:00   cc-by-4.0       0  unknown  2504.04377  \n",
       "5 2025-04-18 03:21:04+00:00        none       0  unknown  2504.04377  \n",
       "6 2025-05-25 04:40:10+00:00   cc-by-4.0       0  unknown        none  \n",
       "7 2025-05-24 04:28:43+00:00   cc-by-4.0       0  unknown        none  \n",
       "8 2025-05-27 12:10:42+00:00  openrail++       1  unknown        none  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560bd56-f02c-4213-af49-b927cf063863",
   "metadata": {},
   "source": [
    "## Ethics, Bias, and Fairness Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ce9c0d-e666-45a5-a99d-0b9a20efaa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageShades/BiasShades 12 2025-05-03 23:25:04+00:00 none 0 unknown none\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"Ethics\", \"Bias\", \"Fairness\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0ed6da-13ec-45cf-9d84-67131eb69fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LanguageShades/BiasShades</td>\n",
       "      <td>12</td>\n",
       "      <td>345</td>\n",
       "      <td>2025-05-03 23:25:04+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dataset ID  Likes  Downloads             Last Modified  \\\n",
       "0  LanguageShades/BiasShades     12        345 2025-05-03 23:25:04+00:00   \n",
       "\n",
       "  License  Models     Size ArXiv  \n",
       "0    none       0  unknown  none  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e6961-59b8-4bc8-b47e-f2b3a2de8173",
   "metadata": {},
   "source": [
    "## Code Generation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f4a462-685f-479d-9123-55f11cab0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"code generation\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a377458f-8894-41e9-acf1-a49b278e18e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35874b-3623-43dd-b1e5-0e592cac34a5",
   "metadata": {},
   "source": [
    "## Official Documentation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d88b2e67-6b5a-4276-ae4b-1fe853d43718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"Documentation\", \"Official Documentation\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83b277c5-5642-40bc-981f-b209a89e78d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a882daa9-abe6-425e-ba48-cb2532ab4373",
   "metadata": {},
   "source": [
    "## Function Call Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cadbabb3-62ec-48ef-bc62-6d1805e0def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# ‚úÖ Filters\n",
    "search_keywords = [\"Function Call\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# ‚úÖ Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # ‚úÖ Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    # ‚úÖ Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# ‚úÖ Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79958255-9ff4-4652-9791-90ea01035dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ae1ae-0568-4b37-b662-56dce754f1db",
   "metadata": {},
   "source": [
    "# Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "183ffe40-2ffe-42d4-bd33-33d80399dd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"table.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"table.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f767e6df-071c-41a5-9d0e-756573cd2f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
