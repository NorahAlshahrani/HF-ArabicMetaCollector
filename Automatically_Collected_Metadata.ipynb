{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babd7231-46ae-4556-955c-03dda1623dc0",
   "metadata": {},
   "source": [
    "# Listing tasks (using filters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0c75f-e085-42b1-860f-6e33a02b3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Mapping the task list to Hugging Face task_categories\n",
    "task_mapping = {\n",
    "    \"Q&A\": \"question-answering\",\n",
    "    \"Reasoning & Multi-step Thinking\": \"reasoning\",\n",
    "    \"Summarization\": \"summarization\",\n",
    "    \"Cultural Alignment\": \"cultural-aligned\",\n",
    "    \"Dialog/Conversation\": \"conversational\",\n",
    "    \"Personal Ownership/System Prompt\": \"System Prompt\",  \n",
    "    \"Robustness & Safety\": \"Safety\",\n",
    "    \"Function Call\": \"function-call\",  \n",
    "    \"Ethics, Bias, and Fairness\": \"bias-and-fairness\",\n",
    "    \"Code Generation\": \"Code Generation\",\n",
    "    \"Official Documentation\": \"documentation\",\n",
    "    \"Translation\": \"translation\"\n",
    "}\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# Loop through each task\n",
    "for user_task, hf_task in task_mapping.items():\n",
    "    print(f\"üîç Processing task: {user_task} ({hf_task})\")\n",
    "    try:\n",
    "        datasets_list = list_datasets(task_categories=hf_task, language=\"ar\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to fetch for task {user_task}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for dataset in datasets_list:\n",
    "        tags = dataset.tags if hasattr(dataset, \"tags\") else []\n",
    "\n",
    "        try:\n",
    "            license = [tag for tag in dataset.tags if \"license\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "\n",
    "\n",
    "        all_rows.append({\n",
    "            \"Task\": user_task,\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        \n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(all_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4dc348-be37-4db4-9dc9-1f0d6a7f2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Task'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51196c-fc81-48a8-8d0d-518a1e92c2ff",
   "metadata": {},
   "source": [
    "# Listing tasks (using keywords):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48262d-e7af-4339-b181-0ca14bb0f1b2",
   "metadata": {},
   "source": [
    "## Cultural Alignment Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3179a-ad1f-478b-b685-f11bafa320a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "#  Filters\n",
    "search_keywords = [\"cultural\", \"culture\", \"cidar\"]\n",
    "required_tags = [\"cultural-aligned\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "#  Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    #  Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    #  Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match or tag_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Tags\": \", \".join(dataset_tags),\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa50af-725d-4315-9be0-471f812c00cc",
   "metadata": {},
   "source": [
    "## Reasoning & Multi-step Thinking Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b270232-b151-434c-9d04-173ef1325847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Reasoning\", \"Multi-step reasoning\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match ):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec938e-545c-4d43-bbeb-1bcfda7425ed",
   "metadata": {},
   "source": [
    "## Dialog/Conversation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d4475-640a-4494-9afb-33e20815566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Dialog\", \"Conversation\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match ):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca41bf-52a0-45ff-8251-82f00fbfb318",
   "metadata": {},
   "source": [
    "## Personal Ownership/System Prompt Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c76db-0bd1-44fd-8669-9baa27acca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"system prompt\", \"persona\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "   \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70239f5b-820c-46b1-98f5-8490cb5486c9",
   "metadata": {},
   "source": [
    "## Robustness & Safety Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd7c6d-b02c-4364-bcdb-5400f1da7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Robustness\", \"Safety\", \"Toxicity\", \"jailbreak\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "  \n",
    "\n",
    "    #  Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560bd56-f02c-4213-af49-b927cf063863",
   "metadata": {},
   "source": [
    "## Ethics, Bias, and Fairness Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce9c0d-e666-45a5-a99d-0b9a20efaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Ethics\", \"Bias\", \"Fairness\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e6961-59b8-4bc8-b47e-f2b3a2de8173",
   "metadata": {},
   "source": [
    "## Code Generation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f4a462-685f-479d-9123-55f11cab0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "#  Filters\n",
    "search_keywords = [\"code generation\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "#  Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "  \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35874b-3623-43dd-b1e5-0e592cac34a5",
   "metadata": {},
   "source": [
    "## Official Documentation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b2e67-6b5a-4276-ae4b-1fe853d43718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Documentation\", \"Official Documentation\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "   \n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a882daa9-abe6-425e-ba48-cb2532ab4373",
   "metadata": {},
   "source": [
    "## Function Call Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbabb3-62ec-48ef-bc62-6d1805e0def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "#  Filters\n",
    "search_keywords = [\"Function Call\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "   \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
