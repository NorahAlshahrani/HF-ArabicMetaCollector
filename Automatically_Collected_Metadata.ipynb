{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babd7231-46ae-4556-955c-03dda1623dc0",
   "metadata": {},
   "source": [
    "# Listing tasks (using filters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5db0c75f-e085-42b1-860f-6e33a02b3968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing task: Q&A (question-answering)\n",
      "üîç Processing task: Reasoning & Multi-step Thinking (reasoning)\n",
      "üîç Processing task: Summarization (summarization)\n",
      "üîç Processing task: Cultural Alignment (cultural-aligned)\n",
      "üîç Processing task: Dialog/Conversation (conversational)\n",
      "üîç Processing task: Personal Ownership/System Prompt (System Prompt)\n",
      "üîç Processing task: Robustness & Safety (Safety)\n",
      "üîç Processing task: Function Call (function-call)\n",
      "üîç Processing task: Ethics, Bias, and Fairness (bias-and-fairness)\n",
      "üîç Processing task: Code Generation (Code Generation)\n",
      "üîç Processing task: Official Documentation (documentation)\n",
      "üîç Processing task: Translation (translation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>openai/MMMLU</td>\n",
       "      <td>486</td>\n",
       "      <td>5173</td>\n",
       "      <td>2024-10-16 18:39:00+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>94</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2009.03300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>google-research-datasets/tydiqa</td>\n",
       "      <td>31</td>\n",
       "      <td>1488</td>\n",
       "      <td>2024-08-08 05:57:11+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>neulab/PangeaInstruct</td>\n",
       "      <td>84</td>\n",
       "      <td>522</td>\n",
       "      <td>2025-02-02 16:40:32+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2410.16153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>hsseinmz/arcd</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>2024-01-09 12:44:24+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q&amp;A</td>\n",
       "      <td>mhardalov/exams</td>\n",
       "      <td>34</td>\n",
       "      <td>1320</td>\n",
       "      <td>2024-02-06 07:20:12+00:00</td>\n",
       "      <td>cc-by-sa-4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2011.03080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Translation</td>\n",
       "      <td>taha-alnasser/ArzEn-CodeMixed</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2025-05-09 03:38:16+00:00</td>\n",
       "      <td>afl-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Translation</td>\n",
       "      <td>Hamzah-Asadullah/TinyDS-20k</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>2025-06-09 09:22:53+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Translation</td>\n",
       "      <td>Groovy-123/deep-think</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>2025-05-22 06:06:36+00:00</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Translation</td>\n",
       "      <td>liboaccn/nmt-parallel-corpus</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>2025-06-01 14:50:19+00:00</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2505.14256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Translation</td>\n",
       "      <td>freococo/quran_multilingual_parallel</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>2025-05-30 12:00:27+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Task                            Dataset ID  Likes  Downloads  \\\n",
       "0            Q&A                          openai/MMMLU    486       5173   \n",
       "1            Q&A       google-research-datasets/tydiqa     31       1488   \n",
       "2            Q&A                 neulab/PangeaInstruct     84        522   \n",
       "3            Q&A                         hsseinmz/arcd      7        300   \n",
       "4            Q&A                       mhardalov/exams     34       1320   \n",
       "..           ...                                   ...    ...        ...   \n",
       "367  Translation         taha-alnasser/ArzEn-CodeMixed      0         19   \n",
       "368  Translation           Hamzah-Asadullah/TinyDS-20k      1        131   \n",
       "369  Translation                 Groovy-123/deep-think      1         77   \n",
       "370  Translation          liboaccn/nmt-parallel-corpus      1         74   \n",
       "371  Translation  freococo/quran_multilingual_parallel      0        120   \n",
       "\n",
       "                Last Modified       License  Models     Size       ArXiv  \n",
       "0   2024-10-16 18:39:00+00:00           mit      94  unknown  2009.03300  \n",
       "1   2024-08-08 05:57:11+00:00    apache-2.0       4  unknown        none  \n",
       "2   2025-02-02 16:40:32+00:00    apache-2.0       6  unknown  2410.16153  \n",
       "3   2024-01-09 12:44:24+00:00           mit       1  unknown        none  \n",
       "4   2024-02-06 07:20:12+00:00  cc-by-sa-4.0       3  unknown  2011.03080  \n",
       "..                        ...           ...     ...      ...         ...  \n",
       "367 2025-05-09 03:38:16+00:00       afl-3.0       0  unknown        none  \n",
       "368 2025-06-09 09:22:53+00:00           mit       0  unknown        none  \n",
       "369 2025-05-22 06:06:36+00:00         other       1  unknown        none  \n",
       "370 2025-06-01 14:50:19+00:00  cc-by-nc-4.0       0  unknown  2505.14256  \n",
       "371 2025-05-30 12:00:27+00:00           mit       0  unknown        none  \n",
       "\n",
       "[372 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Mapping the task list to Hugging Face task_categories\n",
    "task_mapping = {\n",
    "    \"Q&A\": \"question-answering\",\n",
    "    \"Reasoning & Multi-step Thinking\": \"reasoning\",\n",
    "    \"Summarization\": \"summarization\",\n",
    "    \"Cultural Alignment\": \"cultural-aligned\",\n",
    "    \"Dialog/Conversation\": \"conversational\",\n",
    "    \"Personal Ownership/System Prompt\": \"System Prompt\",  \n",
    "    \"Robustness & Safety\": \"Safety\",\n",
    "    \"Function Call\": \"function-call\",  \n",
    "    \"Ethics, Bias, and Fairness\": \"bias-and-fairness\",\n",
    "    \"Code Generation\": \"Code Generation\",\n",
    "    \"Official Documentation\": \"documentation\",\n",
    "    \"Translation\": \"translation\"\n",
    "}\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# Loop through each task\n",
    "for user_task, hf_task in task_mapping.items():\n",
    "    print(f\"üîç Processing task: {user_task} ({hf_task})\")\n",
    "    try:\n",
    "        datasets_list = list_datasets(task_categories=hf_task, language=\"ar\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed to fetch for task {user_task}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for dataset in datasets_list:\n",
    "        tags = dataset.tags if hasattr(dataset, \"tags\") else []\n",
    "\n",
    "        try:\n",
    "            license = [tag for tag in dataset.tags if \"license\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "\n",
    "\n",
    "        all_rows.append({\n",
    "            \"Task\": user_task,\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        \n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(all_rows)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4dc348-be37-4db4-9dc9-1f0d6a7f2395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task\n",
       "Q&A              167\n",
       "Translation      157\n",
       "Summarization     48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Task'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51196c-fc81-48a8-8d0d-518a1e92c2ff",
   "metadata": {},
   "source": [
    "# Listing tasks (using keywords):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48262d-e7af-4339-b181-0ca14bb0f1b2",
   "metadata": {},
   "source": [
    "## Cultural Alignment Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e3179a-ad1f-478b-b685-f11bafa320a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBZUAI/ArabCulture 11 2025-05-23 08:38:06+00:00 cc-by-nc-sa-4.0 0 unknown 2502.12788\n",
      "FreedomIntelligence/ACVA-Arabic-Cultural-Value-Alignment 8 2023-09-21 12:39:18+00:00 apache-2.0 2 unknown none\n",
      "arbml/CIDAR 50 2025-04-03 08:35:36+00:00 apache-2.0 3 unknown 2402.03177\n",
      "arbml/CIDAR-EVAL-100 2 2024-02-14 15:46:10+00:00 apache-2.0 0 unknown 2402.03177\n",
      "arbml/CIDAR-MCQ-100 4 2024-04-02 14:48:39+00:00 apache-2.0 0 unknown 2402.03177\n",
      "QCRI/MultiNativQA 0 2024-10-25 10:59:30+00:00 cc-by-nc-sa-4.0 0 unknown 2407.09823\n",
      "Omartificial-Intelligence-Space/ILMAAM-Arabic-Culturally-Aligned-MMLU 2 2025-02-20 17:22:43+00:00 apache-2.0 0 unknown none\n",
      "HabibaAbderrahim/Tunisian-Proverbs-with-Image-Associations-A-Cultural-and-Linguistic-Dataset 0 2025-05-07 09:16:57+00:00 cc-by-4.0 0 unknown none\n",
      "QCRI/SpokenNativQA 0 2025-05-29 23:03:37+00:00 cc-by-nc-sa-4.0 0 unknown 2505.19163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MBZUAI/ArabCulture</td>\n",
       "      <td>11</td>\n",
       "      <td>822</td>\n",
       "      <td>2025-05-23 08:38:06+00:00</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:multiple-choice, task_categori...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2502.12788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FreedomIntelligence/ACVA-Arabic-Cultural-Value...</td>\n",
       "      <td>8</td>\n",
       "      <td>132</td>\n",
       "      <td>2023-09-21 12:39:18+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>language:ar, license:apache-2.0, size_categori...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arbml/CIDAR</td>\n",
       "      <td>50</td>\n",
       "      <td>261</td>\n",
       "      <td>2025-04-03 08:35:36+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>task_categories:text-generation, language:ar, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2402.03177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arbml/CIDAR-EVAL-100</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-02-14 15:46:10+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:text-generation, language:ar, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2402.03177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arbml/CIDAR-MCQ-100</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "      <td>2024-04-02 14:48:39+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:multiple-choice, language:ar, ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2402.03177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCRI/MultiNativQA</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>2024-10-25 10:59:30+00:00</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:question-answering, language:a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2407.09823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Omartificial-Intelligence-Space/ILMAAM-Arabic-...</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2025-02-20 17:22:43+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>language:ar, license:apache-2.0, size_categori...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HabibaAbderrahim/Tunisian-Proverbs-with-Image-...</td>\n",
       "      <td>0</td>\n",
       "      <td>546</td>\n",
       "      <td>2025-05-07 09:16:57+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:text2text-generation, task_cat...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QCRI/SpokenNativQA</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>2025-05-29 23:03:37+00:00</td>\n",
       "      <td>cc-by-nc-sa-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>task_categories:question-answering, language:a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2505.19163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset ID  Likes  Downloads  \\\n",
       "0                                 MBZUAI/ArabCulture     11        822   \n",
       "1  FreedomIntelligence/ACVA-Arabic-Cultural-Value...      8        132   \n",
       "2                                        arbml/CIDAR     50        261   \n",
       "3                               arbml/CIDAR-EVAL-100      2         24   \n",
       "4                                arbml/CIDAR-MCQ-100      4         69   \n",
       "5                                  QCRI/MultiNativQA      0        293   \n",
       "6  Omartificial-Intelligence-Space/ILMAAM-Arabic-...      2         31   \n",
       "7  HabibaAbderrahim/Tunisian-Proverbs-with-Image-...      0        546   \n",
       "8                                 QCRI/SpokenNativQA      0        142   \n",
       "\n",
       "              Last Modified          License  Models  \\\n",
       "0 2025-05-23 08:38:06+00:00  cc-by-nc-sa-4.0       0   \n",
       "1 2023-09-21 12:39:18+00:00       apache-2.0       2   \n",
       "2 2025-04-03 08:35:36+00:00       apache-2.0       3   \n",
       "3 2024-02-14 15:46:10+00:00       apache-2.0       0   \n",
       "4 2024-04-02 14:48:39+00:00       apache-2.0       0   \n",
       "5 2024-10-25 10:59:30+00:00  cc-by-nc-sa-4.0       0   \n",
       "6 2025-02-20 17:22:43+00:00       apache-2.0       0   \n",
       "7 2025-05-07 09:16:57+00:00        cc-by-4.0       0   \n",
       "8 2025-05-29 23:03:37+00:00  cc-by-nc-sa-4.0       0   \n",
       "\n",
       "                                                Tags     Size       ArXiv  \n",
       "0  task_categories:multiple-choice, task_categori...  unknown  2502.12788  \n",
       "1  language:ar, license:apache-2.0, size_categori...  unknown        none  \n",
       "2  task_categories:text-generation, language:ar, ...  unknown  2402.03177  \n",
       "3  task_categories:text-generation, language:ar, ...  unknown  2402.03177  \n",
       "4  task_categories:multiple-choice, language:ar, ...  unknown  2402.03177  \n",
       "5  task_categories:question-answering, language:a...  unknown  2407.09823  \n",
       "6  language:ar, license:apache-2.0, size_categori...  unknown        none  \n",
       "7  task_categories:text2text-generation, task_cat...  unknown        none  \n",
       "8  task_categories:question-answering, language:a...  unknown  2505.19163  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "#  Filters\n",
    "search_keywords = [\"cultural\", \"culture\", \"cidar\"]\n",
    "required_tags = [\"cultural-aligned\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "#  Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    #  Check for match in name or tag\n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    tag_match = any(tag in dataset_tags for tag in required_tags)\n",
    "\n",
    "    #  Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match or tag_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Tags\": \", \".join(dataset_tags),\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa50af-725d-4315-9be0-471f812c00cc",
   "metadata": {},
   "source": [
    "## Reasoning & Multi-step Thinking Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b270232-b151-434c-9d04-173ef1325847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beetleware/arabic-reasoning-dataset-logic 8 2025-05-21 11:02:11+00:00 mit 0 unknown none\n",
      "MohammedNasser/ARabic_Reasoning_QA 5 2024-09-07 23:00:07+00:00 apache-2.0 1 unknown none\n",
      "MohammedNasser/Arabic_Reasoning_Instruct_QA 2 2024-09-10 07:30:48+00:00 apache-2.0 1 unknown none\n",
      "Omartificial-Intelligence-Space/Arabic_Reasoning_Dataset 9 2024-12-01 08:13:05+00:00 apache-2.0 4 unknown none\n",
      "lightblue/reasoning-multilingual-R1-Llama-70B-train 36 2025-01-31 07:04:20+00:00 apache-2.0 21 unknown none\n",
      "Jr23xd23/Arabic-Optimized-Reasoning-Dataset 2 2025-02-25 13:29:24+00:00 apache-2.0 0 unknown none\n",
      "Pinkstack/OpenHumanreasoning-multilingual-2.2k 2 2025-03-03 17:16:04+00:00 apache-2.0 0 unknown none\n",
      "miscovery/Math_CoT_Arabic_English_Reasoning 16 2025-05-12 00:14:13+00:00 mit 1 unknown none\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beetleware/arabic-reasoning-dataset-logic</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>2025-05-21 11:02:11+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MohammedNasser/ARabic_Reasoning_QA</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2024-09-07 23:00:07+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MohammedNasser/Arabic_Reasoning_Instruct_QA</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>2024-09-10 07:30:48+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Omartificial-Intelligence-Space/Arabic_Reasoni...</td>\n",
       "      <td>9</td>\n",
       "      <td>112</td>\n",
       "      <td>2024-12-01 08:13:05+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightblue/reasoning-multilingual-R1-Llama-70B-...</td>\n",
       "      <td>36</td>\n",
       "      <td>102</td>\n",
       "      <td>2025-01-31 07:04:20+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>21</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jr23xd23/Arabic-Optimized-Reasoning-Dataset</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2025-02-25 13:29:24+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pinkstack/OpenHumanreasoning-multilingual-2.2k</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-03-03 17:16:04+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>miscovery/Math_CoT_Arabic_English_Reasoning</td>\n",
       "      <td>16</td>\n",
       "      <td>264</td>\n",
       "      <td>2025-05-12 00:14:13+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset ID  Likes  Downloads  \\\n",
       "0          beetleware/arabic-reasoning-dataset-logic      8         73   \n",
       "1                 MohammedNasser/ARabic_Reasoning_QA      5         13   \n",
       "2        MohammedNasser/Arabic_Reasoning_Instruct_QA      2         43   \n",
       "3  Omartificial-Intelligence-Space/Arabic_Reasoni...      9        112   \n",
       "4  lightblue/reasoning-multilingual-R1-Llama-70B-...     36        102   \n",
       "5        Jr23xd23/Arabic-Optimized-Reasoning-Dataset      2         34   \n",
       "6     Pinkstack/OpenHumanreasoning-multilingual-2.2k      2         35   \n",
       "7        miscovery/Math_CoT_Arabic_English_Reasoning     16        264   \n",
       "\n",
       "              Last Modified     License  Models     Size ArXiv  \n",
       "0 2025-05-21 11:02:11+00:00         mit       0  unknown  none  \n",
       "1 2024-09-07 23:00:07+00:00  apache-2.0       1  unknown  none  \n",
       "2 2024-09-10 07:30:48+00:00  apache-2.0       1  unknown  none  \n",
       "3 2024-12-01 08:13:05+00:00  apache-2.0       4  unknown  none  \n",
       "4 2025-01-31 07:04:20+00:00  apache-2.0      21  unknown  none  \n",
       "5 2025-02-25 13:29:24+00:00  apache-2.0       0  unknown  none  \n",
       "6 2025-03-03 17:16:04+00:00  apache-2.0       0  unknown  none  \n",
       "7 2025-05-12 00:14:13+00:00         mit       1  unknown  none  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Reasoning\", \"Multi-step reasoning\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match ):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec938e-545c-4d43-bbeb-1bcfda7425ed",
   "metadata": {},
   "source": [
    "## Dialog/Conversation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "308d4475-640a-4494-9afb-33e20815566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mohamedemam/Arabic-samsum-dialogsum 1 2023-09-11 14:35:29+00:00 cc-by-nc-2.0 1 unknown 1911.12237\n",
      "m-ric/Open_Assistant_Conversation_Chains 6 2023-11-22 14:37:58+00:00 apache-2.0 0 unknown none\n",
      "premio-ai/TheArabicPile_Conversational 1 2024-03-21 21:42:33+00:00 cc-by-nc-4.0 0 unknown none\n",
      "Mars203020/arabic_medical_dialogue 3 2024-06-29 11:49:41+00:00 mit 0 unknown none\n",
      "willwade/AACConversations 0 2025-05-15 10:37:50+00:00 cc-by-4.0 0 unknown none\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mohamedemam/Arabic-samsum-dialogsum</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>2023-09-11 14:35:29+00:00</td>\n",
       "      <td>cc-by-nc-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1911.12237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m-ric/Open_Assistant_Conversation_Chains</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>2023-11-22 14:37:58+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>premio-ai/TheArabicPile_Conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-03-21 21:42:33+00:00</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mars203020/arabic_medical_dialogue</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>2024-06-29 11:49:41+00:00</td>\n",
       "      <td>mit</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>willwade/AACConversations</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2025-05-15 10:37:50+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Dataset ID  Likes  Downloads  \\\n",
       "0       mohamedemam/Arabic-samsum-dialogsum      1         41   \n",
       "1  m-ric/Open_Assistant_Conversation_Chains      6         40   \n",
       "2    premio-ai/TheArabicPile_Conversational      1         29   \n",
       "3        Mars203020/arabic_medical_dialogue      3        111   \n",
       "4                 willwade/AACConversations      0         63   \n",
       "\n",
       "              Last Modified       License  Models     Size       ArXiv  \n",
       "0 2023-09-11 14:35:29+00:00  cc-by-nc-2.0       1  unknown  1911.12237  \n",
       "1 2023-11-22 14:37:58+00:00    apache-2.0       0  unknown        none  \n",
       "2 2024-03-21 21:42:33+00:00  cc-by-nc-4.0       0  unknown        none  \n",
       "3 2024-06-29 11:49:41+00:00           mit       0  unknown        none  \n",
       "4 2025-05-15 10:37:50+00:00     cc-by-4.0       0  unknown        none  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Dialog\", \"Conversation\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match ):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca41bf-52a0-45ff-8251-82f00fbfb318",
   "metadata": {},
   "source": [
    "## Personal Ownership/System Prompt Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "275c76db-0bd1-44fd-8669-9baa27acca32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"system prompt\", \"persona\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "   \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70239f5b-820c-46b1-98f5-8490cb5486c9",
   "metadata": {},
   "source": [
    "## Robustness & Safety Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8dd7c6d-b02c-4364-bcdb-5400f1da7933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textdetox/multilingual_toxicity_dataset 27 2025-03-21 18:52:31+00:00 openrail++ 8 unknown none\n",
      "ToxicityPrompts/PolygloToxicityPrompts 11 2024-05-16 07:02:28+00:00 none 0 unknown 2405.09373\n",
      "luizapzbn/from-one-to-many-toxicity-mitigation 0 2024-05-24 17:09:53+00:00 apache-2.0 0 unknown 2403.03893\n",
      "textdetox/multilingual_toxicity_explained 1 2025-02-04 21:03:23+00:00 openrail++ 1 unknown 2412.11691\n",
      "ToxicityPrompts/PolyGuardMix 1 2025-05-16 23:35:00+00:00 cc-by-4.0 0 unknown 2504.04377\n",
      "ToxicityPrompts/PolyGuardPrompts 0 2025-04-18 03:21:04+00:00 none 0 unknown 2504.04377\n",
      "Malikeh1375/tokenizer-robustness-mmlu 0 2025-05-25 04:40:10+00:00 cc-by-4.0 0 unknown none\n",
      "Malikeh1375/code-switching-tokenizer-robustness 1 2025-05-24 04:28:43+00:00 cc-by-4.0 0 unknown none\n",
      "gravitee-io/textdetox-multilingual-toxicity-dataset 0 2025-05-27 12:10:42+00:00 openrail++ 1 unknown none\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textdetox/multilingual_toxicity_dataset</td>\n",
       "      <td>27</td>\n",
       "      <td>797</td>\n",
       "      <td>2025-03-21 18:52:31+00:00</td>\n",
       "      <td>openrail++</td>\n",
       "      <td>8</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ToxicityPrompts/PolygloToxicityPrompts</td>\n",
       "      <td>11</td>\n",
       "      <td>261</td>\n",
       "      <td>2024-05-16 07:02:28+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2405.09373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luizapzbn/from-one-to-many-toxicity-mitigation</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>2024-05-24 17:09:53+00:00</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2403.03893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>textdetox/multilingual_toxicity_explained</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>2025-02-04 21:03:23+00:00</td>\n",
       "      <td>openrail++</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2412.11691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ToxicityPrompts/PolyGuardMix</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>2025-05-16 23:35:00+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2504.04377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ToxicityPrompts/PolyGuardPrompts</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>2025-04-18 03:21:04+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2504.04377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Malikeh1375/tokenizer-robustness-mmlu</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>2025-05-25 04:40:10+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Malikeh1375/code-switching-tokenizer-robustness</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>2025-05-24 04:28:43+00:00</td>\n",
       "      <td>cc-by-4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gravitee-io/textdetox-multilingual-toxicity-da...</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>2025-05-27 12:10:42+00:00</td>\n",
       "      <td>openrail++</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset ID  Likes  Downloads  \\\n",
       "0            textdetox/multilingual_toxicity_dataset     27        797   \n",
       "1             ToxicityPrompts/PolygloToxicityPrompts     11        261   \n",
       "2     luizapzbn/from-one-to-many-toxicity-mitigation      0        193   \n",
       "3          textdetox/multilingual_toxicity_explained      1        129   \n",
       "4                       ToxicityPrompts/PolyGuardMix      1        231   \n",
       "5                   ToxicityPrompts/PolyGuardPrompts      0        134   \n",
       "6              Malikeh1375/tokenizer-robustness-mmlu      0        309   \n",
       "7    Malikeh1375/code-switching-tokenizer-robustness      1        249   \n",
       "8  gravitee-io/textdetox-multilingual-toxicity-da...      0         78   \n",
       "\n",
       "              Last Modified     License  Models     Size       ArXiv  \n",
       "0 2025-03-21 18:52:31+00:00  openrail++       8  unknown        none  \n",
       "1 2024-05-16 07:02:28+00:00        none       0  unknown  2405.09373  \n",
       "2 2024-05-24 17:09:53+00:00  apache-2.0       0  unknown  2403.03893  \n",
       "3 2025-02-04 21:03:23+00:00  openrail++       1  unknown  2412.11691  \n",
       "4 2025-05-16 23:35:00+00:00   cc-by-4.0       0  unknown  2504.04377  \n",
       "5 2025-04-18 03:21:04+00:00        none       0  unknown  2504.04377  \n",
       "6 2025-05-25 04:40:10+00:00   cc-by-4.0       0  unknown        none  \n",
       "7 2025-05-24 04:28:43+00:00   cc-by-4.0       0  unknown        none  \n",
       "8 2025-05-27 12:10:42+00:00  openrail++       1  unknown        none  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Robustness\", \"Safety\", \"Toxicity\", \"jailbreak\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "  \n",
    "\n",
    "    #  Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560bd56-f02c-4213-af49-b927cf063863",
   "metadata": {},
   "source": [
    "## Ethics, Bias, and Fairness Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6ce9c0d-e666-45a5-a99d-0b9a20efaa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageShades/BiasShades 16 2025-05-03 23:25:04+00:00 none 0 unknown none\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>License</th>\n",
       "      <th>Models</th>\n",
       "      <th>Size</th>\n",
       "      <th>ArXiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LanguageShades/BiasShades</td>\n",
       "      <td>16</td>\n",
       "      <td>203</td>\n",
       "      <td>2025-05-03 23:25:04+00:00</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Dataset ID  Likes  Downloads             Last Modified  \\\n",
       "0  LanguageShades/BiasShades     16        203 2025-05-03 23:25:04+00:00   \n",
       "\n",
       "  License  Models     Size ArXiv  \n",
       "0    none       0  unknown  none  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Ethics\", \"Bias\", \"Fairness\"]  \n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "    \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e6961-59b8-4bc8-b47e-f2b3a2de8173",
   "metadata": {},
   "source": [
    "## Code Generation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f4a462-685f-479d-9123-55f11cab0061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "#  Filters\n",
    "search_keywords = [\"code generation\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "#  Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "  \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35874b-3623-43dd-b1e5-0e592cac34a5",
   "metadata": {},
   "source": [
    "## Official Documentation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d88b2e67-6b5a-4276-ae4b-1fe853d43718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "# Filters\n",
    "search_keywords = [\"Documentation\", \"Official Documentation\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "   \n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a882daa9-abe6-425e-ba48-cb2532ab4373",
   "metadata": {},
   "source": [
    "## Function Call Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cadbabb3-62ec-48ef-bc62-6d1805e0def9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import list_datasets, list_models\n",
    "import pandas as pd\n",
    "\n",
    "#  Filters\n",
    "search_keywords = [\"Function Call\"]\n",
    "required_modality = \"modality:text\"\n",
    "\n",
    "# Get only Arabic datasets\n",
    "datasets_list = list_datasets(language=\"ar\")\n",
    "\n",
    "dataset_rows = []\n",
    "\n",
    "for dataset in datasets_list:\n",
    "    dataset_id = dataset.id.lower()\n",
    "    dataset_tags = dataset.tags or []\n",
    "\n",
    "    # Check for match in name \n",
    "    name_match = any(keyword.lower() in dataset_id for keyword in search_keywords)\n",
    "   \n",
    "\n",
    "    # Make sure it's a text dataset\n",
    "    has_text_modality = required_modality in dataset_tags\n",
    "\n",
    "    if has_text_modality and (name_match):\n",
    "        try:\n",
    "            license = [tag for tag in dataset_tags if \"license:\" in tag][0].split(\":\")[-1]\n",
    "        except:\n",
    "            license = \"none\"\n",
    "        try:\n",
    "            models = len(list(list_models(filter=f\"dataset:{dataset.id}\")))\n",
    "        except:\n",
    "            models = \"none\"\n",
    "\n",
    "        size = next((tag.split(\":\")[-1] for tag in dataset_tags if tag.startswith(\"size:\")), \"unknown\")\n",
    "        arxiv_link = next((tag.split(\":\", 1)[-1] for tag in dataset_tags if tag.startswith(\"arxiv:\")), \"none\")\n",
    "\n",
    "        print(dataset.id, dataset.likes, dataset.lastModified, license, models, size, arxiv_link)\n",
    "\n",
    "        dataset_rows.append({\n",
    "            \"Dataset ID\": dataset.id,\n",
    "            \"Likes\": dataset.likes,\n",
    "            \"Downloads\": dataset.downloads,\n",
    "            \"Last Modified\": dataset.lastModified,\n",
    "            \"License\": license,\n",
    "            \"Models\": models,\n",
    "            \"Size\": size,\n",
    "            \"ArXiv\": arxiv_link\n",
    "        })\n",
    "\n",
    "# Create and show DataFrame\n",
    "df = pd.DataFrame(dataset_rows)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
